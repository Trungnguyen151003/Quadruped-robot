import torch
import torch.nn as nn
import torch.nn.functional as F

class Actor(nn.Module):
    def __init__(self, state_dim, action_dim, max_action):
        super(Actor, self).__init__()
        self.layer_1 = nn.Linear(state_dim, 600)
        self.layer_2 = nn.Linear(600, 500)
        self.layer_3 = nn.Linear(500, action_dim)
        self.max_action = max_action

    def forward(self, x):
        x = F.relu(self.layer_1(x))
        x = F.relu(self.layer_2(x))
        x = self.max_action * torch.tanh(self.layer_3(x))
        return x

class Critic(nn.Module):
    def __init__(self, state_dim, action_dim):
        super(Critic, self).__init__()
        # Critic 1
        self.layer_1 = nn.Linear(state_dim + action_dim, 600)
        self.layer_2 = nn.Linear(600, 500)
        self.layer_3 = nn.Linear(500, 1)
        # Critic 2
        self.layer_4 = nn.Linear(state_dim + action_dim, 600)
        self.layer_5 = nn.Linear(600, 500)
        self.layer_6 = nn.Linear(500, 1)

    def forward(self, x, u):
        xu = torch.cat([x, u], 1)
        # Critic 1
        x1 = F.relu(self.layer_1(xu))
        x1 = F.relu(self.layer_2(x1))
        x1 = self.layer_3(x1)
        # Critic 2
        x2 = F.relu(self.layer_4(xu))
        x2 = F.relu(self.layer_5(x2))
        x2 = self.layer_6(x2)
        return x1, x2

    def Q1(self, x, u):
        xu = torch.cat([x, u], 1)
        x1 = F.relu(self.layer_1(xu))
        x1 = F.relu(self.layer_2(x1))
        x1 = self.layer_3(x1)
        return x1
